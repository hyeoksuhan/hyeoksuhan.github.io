---
title: fluentd로 서버 로그 통합
layout: post
tags: fluentd in_tail
categories: fluentd
---
API 서버 로그가 파일로 쌓고 있으며 날짜별로 쪼개서(daily rotation) 저장을 하고 있었다
로그의 내용은 API 전체 플로우와 기타 중요한 정보를 저장하고 있었기에 백업이 필요했다
서버의 crontab으로 하루에 한번씩 parsing, filtering후에 s3에 업로드 하고 s3에 업로드 되면 lambda에 의해서 데이터 타입별로 재가공, RDS에 저장 되는 구조였다

위와 같은 구성은 로그의 저장 및 처리를 각 서버에서 따로 구성 하기도 까다롭고 scale in/out이 발생하게 되면 서버의 로컬에 저장된 로그 파일은 유실의 위험도 컸기에 불합리 하다고 판단이 되었다

그래서 fluentd를 이용해서 각 서버에서 발생하는 로그를 한곳(로그 서버)으로 모으기로 결정했다
우선 첫단계로 현재 쌓고 있는 파일을 in_tail 플러그인으로 읽은 후에 로그 서버로 forward 시키고 log 서버에서는 file로 통합 저장해보기로 했다
<!--more-->
현재 돌아가고 있는 서버에 성능적으로 영향을 주지 않고 코드 수정이 없도록 하기 위함과 로그의 통합만 잘 된다면 추후에 fluentd의 out 플러그인만 적절히 바꿔주면 target을 elastic search나 AWS kinesis로 쉽게 변경이 가능할 것 같다고 판단해서이다

in_tail 플러그인은 쉘 명령어의 tail -f의 output을 가져오는 것과 비슷한데 `read_from_head`옵션을 True로 설정하면 파일의 끝부분이 아닌 첫행 부터 읽을 수도 있다
로그가 날짜별로 쪼개지기 때문에 읽어들이는 파일명이 낢짜에 따라 동적으로 변해야 했기 때문에 path에 %Y%m%d를 사용했다

API 서버에서 로그파일명이 2019-11-07-main-api.log의 포맷이라 `path %Y-%m-%d-main-api.log`와 같이 설정했다
%Y%m%d의 timezone은 따로 설정할 수 없고 os의 timezone 설정에 따르도록 되어있다.

ansible로 AMI로 구성해 ec2에 설치 및 설정 되도록 했고 현재는 local에서 role로 정의를 했으나 추후에 따로 분리할 예정이다

로그 통합저장을 위한 td-agent 설정은 아래와 같다

## API서버(로그를 내보내는 쪽) 설정
**/etc/td-agent/td-agent.conf**

```
@include /etc/td-agent/conf.d/*.conf
```

fluetnd agent의 메인 설정파일로 ./conf.d에 있는 모든 설정파일을 포함하도록 설정했는데
conf.d에는 플러그인 타입별로 분리하여 걸정파일을 두었고 이렇게 분리하여 관리했을 때의 장점은 직관적이고 유지보수가 편하다

**/etc/td-agent/conf.d/source.conf**

```
<source>
  @type tail
  tag api.log
  rotate_wait 36000
  read_lines_limit 5000
  read_from_head True
  pos_file /var/log/td-agent/in_tail.log.pos
  path /home/ec2-user/app/logs/%Y-%m-%d-main-api.log
  <parse>
    @type multiline
    format_firstline /\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{3}Z/
    format1 /^(?<timestamp>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{3}Z) (?<level>[^\s]+) (?<tag>[^\s]+) (?<message>.*)/
  </parse>
  multiline_flush_interval 5s
</source>
```

\<parse\>의 type을 multiline으로 한 이유는 아직 로그 포맷이 정형화 되지 않아서 에러로그도 같이 찍고 있는데 multiline으로 하지 않으면 stack trace가 첫번째 라인까지만 읽어들이기 때문이다

tag를 api.log로 설정했고 이 tag는 match에서 출력을 맵핑할 때 id 역할을 한다
rotate_wait는 대상 파일이 동적으로 변할때 이전 파일을 얼마동안 참조 유지를 하겠냐는 설정으로 적절히 설정해주어 대상 파일이 변할 때 로그의 손실이 없도록 해야 한다
현재 설정은 36000으로 설정했고 단위가 second 이므로 10시간으로 설정했는데 이유는 로그 저장시에는 UTC, os timezone은 KST라서 9시간 차이가 나는 이슈 때문이었고 이미 가동중인 서버라 수정이 힘든 부분이 있어 이렇게 설정을 했다

**/etc/td-agent/conf.d/match.conf**

```
<match api.log>
  @type forward
  <server>
    weight 60
    port 24224
    name logserver
    host <로그 서버의 host>
  </server>
  flush_interval 10s
  flush_at_shutdown True
  buffer_type file
  buffer_path /var/log/td-agent/forward.buffer

</match>
```
buffer_type은 file로 설정하여 memory보다는 속도 측면에서는 느리지만 데이터 손실의 위험을 줄일 수 있어서 선택을 했다
flush_at_shutdown을 true로 설정하면 agent가 종료될 떄 buffer를 flush 할도록 설정을 했고 default는 false다

\<server\>는 forwarding할 로그서버를 지정해주면 된다.


## Log 서버(match에서 \<server\>로 지정) 설정

**/etc/td-agent/td-agent.conf**

```
<source>
  @type forward
  port 24224
</source>

<match api.log>
  @type file
  path /logs/api
  time_slice_format %Y%m%d
</match>
```

API 서버가 forward한 내용을 source를 통해 받아서 /logs 디렉토리에 저장하는 설정이다

위와 같이 설정하면 /logs에 /api라는 디렉토리가 생기고 파일로 버퍼링이 된다
버퍼링이 되다가 어느시점(정확히는 찾아보지 않았는데 기본 설정된 값에 따라 flush가 되는 듯)에 flush가 되면 /logs 디렉토리에 api.20200101_0.log와 같이 파일로 저장이 된다

현재는 API 서버의 output을 kinesis firehose 플러그인을 써서 s3에 저장하고 조건에 따라 로그를 분리하 각각 람다가 용도에 맞게 가공후 DB에 저장하도록 구성이 되어 있는데 다음에 정리 예정이다

